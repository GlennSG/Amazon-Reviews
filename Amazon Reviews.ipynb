{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we'll be performing a sentiment analysis on \"Health and Personal Care\" product reviews from Amazon. The goal is create a model that can accurately classify whether a review a positive or negative based on its text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159985130X</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a great little gadget to have around. ...</td>\n",
       "      <td>01 5, 2011</td>\n",
       "      <td>ALC5GH8CAMAI7</td>\n",
       "      <td>AnnN</td>\n",
       "      <td>Handy little gadget</td>\n",
       "      <td>1294185600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159985130X</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I would recommend this for a travel magnifier ...</td>\n",
       "      <td>02 18, 2012</td>\n",
       "      <td>AHKSURW85PJUE</td>\n",
       "      <td>AZ buyer \"AZ buyer\"</td>\n",
       "      <td>Small &amp; may need to encourage battery</td>\n",
       "      <td>1329523200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159985130X</td>\n",
       "      <td>[75, 77]</td>\n",
       "      <td>4</td>\n",
       "      <td>What I liked was the quality of the lens and t...</td>\n",
       "      <td>06 8, 2010</td>\n",
       "      <td>A38RMU1Y5TDP9</td>\n",
       "      <td>Bob Tobias \"Robert Tobias\"</td>\n",
       "      <td>Very good but not great</td>\n",
       "      <td>1275955200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin   helpful  overall  \\\n",
       "0  159985130X    [1, 1]        5   \n",
       "1  159985130X    [1, 1]        4   \n",
       "2  159985130X  [75, 77]        4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  This is a great little gadget to have around. ...   01 5, 2011   \n",
       "1  I would recommend this for a travel magnifier ...  02 18, 2012   \n",
       "2  What I liked was the quality of the lens and t...   06 8, 2010   \n",
       "\n",
       "      reviewerID                reviewerName  \\\n",
       "0  ALC5GH8CAMAI7                        AnnN   \n",
       "1  AHKSURW85PJUE         AZ buyer \"AZ buyer\"   \n",
       "2  A38RMU1Y5TDP9  Bob Tobias \"Robert Tobias\"   \n",
       "\n",
       "                                 summary  unixReviewTime  \n",
       "0                    Handy little gadget      1294185600  \n",
       "1  Small & may need to encourage battery      1329523200  \n",
       "2                Very good but not great      1275955200  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_data = pd.read_json(\"Health_and_Personal_Care_5.json\",lines=True)\n",
    "amazon_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346355, 9)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                 0\n",
       "helpful              0\n",
       "overall              0\n",
       "reviewText           0\n",
       "reviewTime           0\n",
       "reviewerID           0\n",
       "reviewerName      3051\n",
       "summary              0\n",
       "unixReviewTime       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most relevant features for our model appear to be \"overall\" and \"reviewText\". For simplicty, we'll say any \"overall\" value greater than or equal to 4 would indicate a positive rating. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text_data):\n",
    "    text = re.sub(\"[^a-zA-Z]\",' ',text_data)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    lmz = WordNetLemmatizer()\n",
    "    text = [lmz.lemmatize(word) for word in text if not word in set(stopwords.words('english'))]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is rather large for making a bag of words model. The time to clean all 346,355 texts would be too much for an average computer to handle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a great little gadget to have around. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would recommend this for a travel magnifier ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What I liked was the quality of the lens and t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText\n",
       "0  This is a great little gadget to have around. ...\n",
       "1  I would recommend this for a travel magnifier ...\n",
       "2  What I liked was the quality of the lens and t..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz = amazon_data[[\"reviewText\"]]\n",
    "amz.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try selecting 25% of our data to make our sample\n",
    "amz = amz.sample(frac=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86589, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for text in amz[\"reviewText\"]:\n",
    "    clean_text = text_cleaner(text)\n",
    "    corpus.append(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86589"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create our \"sentiment\" dependent variable \"Rating\"\n",
    "from textblob import TextBlob\n",
    "amz[\"cleanText\"] = corpus\n",
    "amz[\"Rating\"] = amz[\"cleanText\"].apply(lambda x: TextBlob(x).sentiment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make dependent variable with 1 indicating positive review and 0 indicating negative review\n",
    "amz[\"RatingScore\"] = np.where(amz[\"Rating\"] > 0, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>Rating</th>\n",
       "      <th>RatingScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64943</th>\n",
       "      <td>I keep my scruff trimmed up great with this. W...</td>\n",
       "      <td>keep scruff trimmed great included guard go cl...</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270734</th>\n",
       "      <td>Great quality and smell could even be worn alo...</td>\n",
       "      <td>great quality smell could even worn alone care...</td>\n",
       "      <td>0.215000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75565</th>\n",
       "      <td>Gaia Herbs comes through again with this fabul...</td>\n",
       "      <td>gaia herb come fabulous product liquid high qu...</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  \\\n",
       "64943   I keep my scruff trimmed up great with this. W...   \n",
       "270734  Great quality and smell could even be worn alo...   \n",
       "75565   Gaia Herbs comes through again with this fabul...   \n",
       "\n",
       "                                                cleanText    Rating  \\\n",
       "64943   keep scruff trimmed great included guard go cl...  0.291667   \n",
       "270734  great quality smell could even worn alone care...  0.215000   \n",
       "75565   gaia herb come fabulous product liquid high qu...  0.386667   \n",
       "\n",
       "        RatingScore  \n",
       "64943             1  \n",
       "270734            1  \n",
       "75565             1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_v = TfidfVectorizer(\n",
    "    max_df = 0.5,\n",
    "    min_df = 2,\n",
    "    use_idf = True,\n",
    "    norm = u'l2',\n",
    "    smooth_idf = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_v.fit_transform(amz[\"cleanText\"])\n",
    "y = amz.iloc[:,3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86589, 27890)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score:  0.8099665088347384\n"
     ]
    }
   ],
   "source": [
    "print(\"Model accuracy score: \", clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying out Bernoulli Naive Bayes to see if there's a difference in accuracy (using tfidf matrix)\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clfb = BernoulliNB()\n",
    "clfb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score:  0.7730107402702391\n"
     ]
    }
   ],
   "source": [
    "print(\"Model accuracy score: \", clfb.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears Multinomial Naive Bayes performed better than the Bernoulli Naive Bayes algorithm for this dataset. This is most likely due to the fact that the tfidf matrix works better with Multinomial Naive Bayes than Bernoulli Naive Bayes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score:  0.8559302459868345\n"
     ]
    }
   ],
   "source": [
    "print(\"Model accuracy score: \", logreg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score:  0.8211687261808522\n"
     ]
    }
   ],
   "source": [
    "print(\"Model accuracy score: \", rfc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgc = XGBClassifier()\n",
    "xgc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score:  0.820418062131886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glenn/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "print(\"Model accuracy score: \", xgc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all the models used above, Logistic Regression had the highest accuracy. This could be attributed by how we set up our independent and dependent features (converting our dependent feature to binary values). It was a surprise to see how accurate the Naive Bayes models turned out, was not sure how the models would work with the tfidf matrix of independent features. Also, the ensemble models appear to be not overfitting, but cannot say for certain since trying to use cross validation with this large dataset would be time inefficient. \n",
    "\n",
    "Lets explore the Logistic model further..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1287  2044]\n",
      " [  451 13536]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviews correctly classified: 14823/17318 (85.59%) \n",
    "\n",
    "Reviews incorrectly classified: 2495/17318 (14.41%) \n",
    "\n",
    "False Positive: 451/13987 (identified positive but negative review)\n",
    "\n",
    "False Negative: 2044/3331 (identified negative but positive review)\n",
    "\n",
    "Sensitivity: 13536/13987 (positive reviews correctly classified)\n",
    "\n",
    "Specificity: 1287/3331 (negative reviews correctly classified)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
